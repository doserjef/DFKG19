dat <- dat %>%
mutate(PSD10 = logit(PSD10, 0, 1))
}
}
long.dat <- gather(dat, key = "index", value = "value", indexNames)
# Order data by each "individual" recording site/day/time combo
ordered.long.dat <- long.dat %>%
arrange(recording.site, day, time, year)
ordered.long.dat$X <- NULL
n <- nrow(ordered.long.dat)
head(ordered.long.dat)
head(ordered.long.dat, 40)
r < - 3
r <- 3
R <- diag(0.1, 14)
test <- rWishart(1000, r, R * r)
test <- rWishart(1000, r, r * R)
test <- rWishart(1000, r, chol2inv(chol(r * R))
)
?rWishart
rm(list = ls())
source("multivarSoundModel.R")
library(coda)
library(corrplot)
library(ggplot2)
library(dplyr)
# Run model ---------------------------------------------------------------
n.iter <- 500
fileName <- "../../data/orderedMultivariateData.csv"
geoFileName <- "../../data/geophony.csv"
indexNames <- c('H', 'aci', 'ndsi', 'aei', paste('PSD', 1:10, sep = ''))
yearsPostTrt <- 2014:2018
alpha.start <- 1
beta.start <- 0
sigma.sq.start <- 1
lambda.start <- 1
out1 <- multivar.sound.model(n.iter = n.iter,
fileName,
geoFileName,
indexNames,
yearsPostTrt,
alpha.start,
beta.start,
sigma.sq.start,
lambda.start)
alpha.samples <- out1$alpha.samples
beta.samples <- out1$beta.samples
sigma.sq.samples <- out1$sigma.sq.samples
lambda.samples <- out1$lambda.samples
# I currently commented out this part of the model just to speed it up,
# because you're not
# actually using the fitted values for anything.
fitted.samples <- out1$fitted.samples
burn.in <- floor(0.1 * n.iter)
sub <- (burn.in+1):n.iter
# alpha
alpha.vals <- summary(window(mcmc(t(alpha.samples)), start = burn.in))$quantiles
# sigma.sq
summary(window(mcmc(sigma.sq.samples)), start = burn.in)
corr.med <- cov2cor(lambda.med.mat)
colnames(corr.med) <- toupper(indexNames)
rownames(corr.med) <- toupper(indexNames)
corr.low <- cov2cor(lambda.lower.mat)
colnames(corr.low) <- toupper(indexNames)
rownames(corr.low) <- toupper(indexNames)
corr.high <- cov2cor(lambda.upper.mat)
colnames(corr.high) <- toupper(indexNames)
rownames(corr.high) <- toupper(indexNames)
sig.mat <- matrix(0, nrow(corr.med), ncol(corr.med))
# Note that 0 denotes "significant", 1 denotes "insignificant
sig.mat <- ifelse((0 > corr.low) & (0 < corr.high), 1, 0)
vals <- summary(window(mcmc(t(lambda.samples)), start = burn.in))$quantiles
n.indices <- length(indexNames)
lambda.med.mat <- matrix(vals[, 3], nrow = n.indices)
cov2cor(lambda.med.mat)
lambda.lower.mat <- matrix(vals[, 1], nrow = n.indices)
lambda.upper.mat <- matrix(vals[, 5], nrow = n.indices)
cov2cor(lambda.lower.mat)
cov2cor(lambda.upper.mat)
# Good way to visualize the correlation matrix
corr.med <- cov2cor(lambda.med.mat)
colnames(corr.med) <- toupper(indexNames)
rownames(corr.med) <- toupper(indexNames)
corr.low <- cov2cor(lambda.lower.mat)
colnames(corr.low) <- toupper(indexNames)
rownames(corr.low) <- toupper(indexNames)
corr.high <- cov2cor(lambda.upper.mat)
colnames(corr.high) <- toupper(indexNames)
rownames(corr.high) <- toupper(indexNames)
sig.mat <- matrix(0, nrow(corr.med), ncol(corr.med))
# Note that 0 denotes "significant", 1 denotes "insignificant
sig.mat <- ifelse((0 > corr.low) & (0 < corr.high), 1, 0)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr.med, method="color", col=col(200),
type="upper",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=FALSE,
# "Significance"
p.mat = sig.mat, sig.level = 0.5, insig = 'blank'
)
alpha.vals
# A single plot for a single index
rownames(alpha.vals) <- paste(rep(indexNames, each = 13), 1:13, sep = "")
plot.dat <- data.frame(low = alpha.vals[, 1],
med = alpha.vals[, 3],
high = alpha.vals[, 5],
alpha = rep(1:13, n.indices),
index = rep(indexNames, each = 13))
plot.trt.dat <- plot.dat %>%
filter(alpha %in% c(8:12))
plot.trt.dat$year <- rep(2014:2018, n.indices)
plot.trt.dat$index <- toupper(plot.trt.dat$index)
plot.trt.dat$index <- factor(plot.trt.dat$index,
levels = c('H', 'ACI', 'NDSI', 'AEI',
"PSD1", "PSD2", "PSD3", 'PSD4',
'PSD5', 'PSD6', 'PSD7', 'PSD8',
'PSD9', 'PSD10'))
plot.names <- c(
`H` = 'scriptstyle(bgroup("", a, ")"))~H',
`ACI` = 'scriptstyle(bgroup("", b, ")"))~ACI',
`NDSI` = 'scriptstyle(bgroup("", c, ")"))~NDSI',
`AEI` = 'scriptstyle(bgroup("", d, ")"))~AEI',
`PSD1` = 'scriptstyle(bgroup("", e, ")"))~PSD[1]',
`PSD2` = 'scriptstyle(bgroup("", f, ")"))~PSD[2]',
`PSD3` = 'scriptstyle(bgroup("", g, ")"))~PSD[3]',
`PSD4` = 'scriptstyle(bgroup("", h, ")"))~PSD[4]',
`PSD5` = 'scriptstyle(bgroup("", i, ")"))~PSD[5]',
`PSD6` = 'scriptstyle(bgroup("", j, ")"))~PSD[6]',
`PSD7` = 'scriptstyle(bgroup("", k, ")"))~PSD[7]',
`PSD8` = 'scriptstyle(bgroup("", l, ")"))~PSD[8]',
`PSD9` = 'scriptstyle(bgroup("", m, ")"))~PSD[9]',
`PSD10` = 'scriptstyle(bgroup("", n, ")"))~PSD[10]'
)
theme_set(theme_bw(base_size = 18))
ggplot(data = plot.trt.dat, aes(x = year)) +
geom_point(aes(y = med)) +
geom_segment(aes(x = year, y = low, xend = year, yend = high),
color = 'red') +
facet_wrap(index ~ ., scales = "free_y", ncol = 3,
labeller = as_labeller(plot.names, label_parsed)) +
geom_hline(yintercept = 0, linetype = 'dashed', col = 'black') +
labs(x = 'Year', y = 'Year Effect') +
theme(axis.text=element_text(size=14),
axis.title=element_text(size=18),
plot.margin = margin(t = 16, r = 16, b = 0, l = 5, unit = "pt"))
#  Check out the non-treatment effects ------------------------------------
alpha.nontrt.out <- alpha.vals[2:171, ]
nontrt.out <- alpha.nontrt.out[seq(1, nrow(alpha.nontrt.out), 13), ]
nontrt.out
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
png("../../figures/correlationDiagram.png")
corrplot(corr.med, method="color", col=col(200),
type="upper",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=FALSE,
# "Significance"
p.mat = sig.mat, sig.level = 0.5, insig = 'blank'
)
dev.off()
# A single plot for a single index
rownames(alpha.vals) <- paste(rep(indexNames, each = 13), 1:13, sep = "")
plot.dat <- data.frame(low = alpha.vals[, 1],
med = alpha.vals[, 3],
high = alpha.vals[, 5],
alpha = rep(1:13, n.indices),
index = rep(indexNames, each = 13))
plot.trt.dat <- plot.dat %>%
filter(alpha %in% c(8:12))
plot.trt.dat$year <- rep(2014:2018, n.indices)
plot.trt.dat$index <- toupper(plot.trt.dat$index)
plot.trt.dat$index <- factor(plot.trt.dat$index,
levels = c('H', 'ACI', 'NDSI', 'AEI',
"PSD1", "PSD2", "PSD3", 'PSD4',
'PSD5', 'PSD6', 'PSD7', 'PSD8',
'PSD9', 'PSD10'))
plot.names <- c(
`H` = 'scriptstyle(bgroup("", a, ")"))~H',
`ACI` = 'scriptstyle(bgroup("", b, ")"))~ACI',
`NDSI` = 'scriptstyle(bgroup("", c, ")"))~NDSI',
`AEI` = 'scriptstyle(bgroup("", d, ")"))~AEI',
`PSD1` = 'scriptstyle(bgroup("", e, ")"))~PSD[1]',
`PSD2` = 'scriptstyle(bgroup("", f, ")"))~PSD[2]',
`PSD3` = 'scriptstyle(bgroup("", g, ")"))~PSD[3]',
`PSD4` = 'scriptstyle(bgroup("", h, ")"))~PSD[4]',
`PSD5` = 'scriptstyle(bgroup("", i, ")"))~PSD[5]',
`PSD6` = 'scriptstyle(bgroup("", j, ")"))~PSD[6]',
`PSD7` = 'scriptstyle(bgroup("", k, ")"))~PSD[7]',
`PSD8` = 'scriptstyle(bgroup("", l, ")"))~PSD[8]',
`PSD9` = 'scriptstyle(bgroup("", m, ")"))~PSD[9]',
`PSD10` = 'scriptstyle(bgroup("", n, ")"))~PSD[10]'
)
png("../../figures/multivariateTreatmentEffects.png", height = 780, width = 650)
theme_set(theme_bw(base_size = 18))
ggplot(data = plot.trt.dat, aes(x = year)) +
geom_point(aes(y = med)) +
geom_segment(aes(x = year, y = low, xend = year, yend = high),
color = 'red') +
facet_wrap(index ~ ., scales = "free_y", ncol = 3,
labeller = as_labeller(plot.names, label_parsed)) +
geom_hline(yintercept = 0, linetype = 'dashed', col = 'black') +
labs(x = 'Year', y = 'Year Effect') +
theme(axis.text=element_text(size=14),
axis.title=element_text(size=18),
plot.margin = margin(t = 16, r = 16, b = 0, l = 5, unit = "pt"))
dev.off()
#  Check out the non-treatment effects ------------------------------------
alpha.nontrt.out <- alpha.vals[2:171, ]
nontrt.out <- alpha.nontrt.out[seq(1, nrow(alpha.nontrt.out), 13), ]
nontrt.out
# Rain Effect
alpha.out.sub <- alpha.vals[13:182, ]
rain.out <- alpha.out.sub[seq(1, nrow(alpha.out.sub), 13), ]
rain.out
rmvn <- function(n, mu=0, V = matrix(1)){
p <- length(mu)
if(any(is.na(match(dim(V),p))))
stop("Dimension problem!")
D <- chol(V)
t(matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}
# Logit data transformation
logit <- function(theta, a, b) {
log((theta-a)/(b-theta))
}
# Inverse logit transformation
logit.inv <- function(z, a, b) {
b-(b-a)/(1+exp(z))
}
set.seed(1)
rmvn <- function(n, mu=0, V = matrix(1)){
p <- length(mu)
if(any(is.na(match(dim(V),p))))
stop("Dimension problem!")
D <- chol(V)
t(matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}
# Logit data transformation
logit <- function(theta, a, b) {
log((theta-a)/(b-theta))
}
# Inverse logit transformation
logit.inv <- function(z, a, b) {
b-(b-a)/(1+exp(z))
}
set.seed(1)
n <- n.sites * n.dc * n.days * n.years * n.indices
n.ind <- n.days * n.dc * n.sites * n.indices
n.ind.one <- n.days * n.dc * n.sites
n.sites = 13
n.dc = 4
n.days = 30
n.years = 5
n.indices = 10
n.alpha <- ((n.years - 1) * 2 + 2) * n.indices
# Fixed effect coefficients
alpha <- rnorm(n.alpha, 0, 2)
rmvn <- function(n, mu=0, V = matrix(1)){
p <- length(mu)
if(any(is.na(match(dim(V),p))))
stop("Dimension problem!")
D <- chol(V)
t(matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}
# Logit data transformation
logit <- function(theta, a, b) {
log((theta-a)/(b-theta))
}
# Inverse logit transformation
logit.inv <- function(z, a, b) {
b-(b-a)/(1+exp(z))
}
# Simulate Data -----------------------------------------------------------
set.seed(1)
n <- n.sites * n.dc * n.days * n.years * n.indices
n.ind <- n.days * n.dc * n.sites * n.indices
n.ind.one <- n.days * n.dc * n.sites
n.alpha <- ((n.years - 1) * 2 + 2) * n.indices
# Fixed effect coefficients
alpha <- rnorm(n.alpha, 0, 2)
# Process variance
Sigma.sq <- diag(sigma.sq, n.indices)
sigma.sq = 1
rmvn <- function(n, mu=0, V = matrix(1)){
p <- length(mu)
if(any(is.na(match(dim(V),p))))
stop("Dimension problem!")
D <- chol(V)
t(matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}
# Logit data transformation
logit <- function(theta, a, b) {
log((theta-a)/(b-theta))
}
# Inverse logit transformation
logit.inv <- function(z, a, b) {
b-(b-a)/(1+exp(z))
}
# Simulate Data -----------------------------------------------------------
set.seed(1)
n <- n.sites * n.dc * n.days * n.years * n.indices
n.ind <- n.days * n.dc * n.sites * n.indices
n.ind.one <- n.days * n.dc * n.sites
n.alpha <- ((n.years - 1) * 2 + 2) * n.indices
# Fixed effect coefficients
alpha <- rnorm(n.alpha, 0, 2)
# Process variance
Sigma.sq <- diag(sigma.sq, n.indices)
# Random effect covariance matrix
lambda <- matrix(0, nrow = n.indices, ncol = n.indices)
diag(lambda) <- 1.5
lambda[2, 2] <- .4
lambda[3, 3] <- .9
# Individual random effects
n.beta <- 1
beta.mu <- rep(0, n.indices)
beta.mat <- rmvn(n.ind.one, beta.mu, lambda)
beta <- c(beta.mat)
n.trt <- 4
n.ctrl <- n.sites - n.trt
# Create treatment groups
trt.ind <- rep(0, n)
trt.ind[1:(6000*n.trt)] <- 1
year <- rep(rep(c(2013, 2014, 2015, 2016, 2017), each = n.indices), length.out = n)
psd.ind <- rep(1:n.indices, length.out = n)
X <- matrix(0, ncol = ((n.years - 1) * 2 + 2) * n.indices, nrow = n)
# Create treatment groups
trt.ind <- rep(0, n)
trt.ind[1:(6000*n.trt)] <- 1
year <- rep(rep(c(2013, 2014, 2015, 2016, 2017), each = n.indices), length.out = n)
index.ind <- rep(1:n.indices, length.out = n)
X <- matrix(0, ncol = ((n.years - 1) * 2 + 2) * n.indices, nrow = n)
num <- ncol(X) / n.indices
for (i in 1:n.indices) {
# Respective intercept for each
X[, (i-1)*num + 1] <- ifelse(index.ind == i, 1, 0)
X[, (i-1)*num + 2] <- ifelse(index.ind == i & trt.ind == 1, 1, 0)
X[, (i-1)*num + 3] <- ifelse(index.ind == i & year == 2014, 1, 0)
X[, (i-1)*num + 4] <- ifelse(index.ind == i & year == 2015, 1, 0)
X[, (i-1)*num + 5] <- ifelse(index.ind == i & year == 2016, 1, 0)
X[, (i-1)*num + 6] <- ifelse(index.ind == i & year == 2017, 1, 0)
X[, (i-1)*num + 7] <- ifelse(index.ind == i & year == 2014 & trt.ind == 1, 1, 0)
X[, (i-1)*num + 8] <- ifelse(index.ind == i & year == 2015 & trt.ind == 1, 1, 0)
X[, (i-1)*num + 9] <- ifelse(index.ind == i & year == 2016 & trt.ind == 1, 1, 0)
X[, (i-1)*num + 10] <- ifelse(index.ind == i & year == 2017 & trt.ind == 1, 1, 0)
}
# Indicator for individual
ind <- rep(1:n.ind.one, each = n.years * n.indices)
# Construct likelihood
I.s <- diag(1, n.years)
V <- kronecker(I.s, Sigma.sq)
y <- rep(0, n)
for (i in 1:n.ind.one) {
x.i <- X[ind == i, ]
# W.i <- W[ind == i, ]
# v <- x.i %*% alpha + rep(1, n.years)*beta.0[i] + w.i * beta.1[i]
v <- x.i %*% alpha + beta[((i-1)*n.indices + 1):(((i-1)*n.indices) + n.indices)]
y[((i-1)*n.years*n.indices + 1):(((i-1)*n.years*n.indices)+n.years*n.indices)] <- rmvn(n = 1, mu = v, V = V)
}
rm(list = ls())
source("sim.R")
source("multivarSoundModel.R")
library(coda)
rm(list = ls())
source("sim.R")
source("multivarSoundModel.R")
library(coda)
# This is the main program for testing the multivariate model with simulated
# data
# Author: Jeffrey W. Doser
# Main Program ------------------------------------------------------------
# Multivariate normal random number generator
rmvn <- function(n, mu=0, V = matrix(1)){
p <- length(mu)
if(any(is.na(match(dim(V),p))))
stop("Dimension problem!")
D <- chol(V)
t(matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}
# Inverse Gamma random number generator
rigamma <- function(n, a, b){
1/rgamma(n = n, shape = a, rate = b)
}
# Inverse Wishart random number generator
riWishart <- function(n, df, Sigma) {
1/rWishart(n = n, df = df, Sigma = Sigma)
}
# Simulate the data
dat <- sim.multi.dat()
str(dat)
rm(list = ls())
source("sim.R")
source("sim-multivarSoundModel.R")
source("sim-multivariateSoundModel.R")
library(coda)
# Simulate the data
dat <- sim.multi.dat()
rm(list = ls())
source("sim.R")
source("sim-multivariateSoundModel.R")
library(coda)
# This is the main program for testing the multivariate model with simulated
# data
# Author: Jeffrey W. Doser
# Main Program ------------------------------------------------------------
# Simulate the data
dat <- sim.multi.dat()
out <- sim.multivar.sound.model(n.iter = 300,
X = dat$X,
y = dat$y,
n.sites = dat$n.sites,
n.indices = nrow(dat$lambda),
ind = dat$ind,
alpha.start = 0,
beta.start = 0,
sigma.sq.start = 1,
lambda.start = 1)
# Look at process varaince
plot(mcmc(sigma.sq.samples), density = FALSE)
n.iter <- 300
sigma.sq.samples <- out$sigma.sq.samples
lambda.samples <- out$lambda.samples
alpha.samples <- out$alpha.samples
beta.samples <- out$beta.samples
# Look at process varaince
plot(mcmc(sigma.sq.samples), density = FALSE)
# Lambda covariance matrix
summary(mcmc(t(lambda.samples)))
# Burn in
burn.in <- floor(0.5 * n.samples)
sub <- (burn.in+1):n.samples
# Burn in
burn.in <- floor(0.5 * n.iter)
sub <- (burn.in+1):n.iter
# Fixed coefficients
alpha.hat.mean <- apply(alpha.samples[, sub], 1, mean)
plot(alpha.true[, 1], alpha.hat.mean, pch = 19)
# Burn in. Can change the 0.5 to change the amount of burn.in required
burn.in <- floor(0.5 * n.iter)
sub <- (burn.in+1):n.iter
# Fixed coefficients
alpha.hat.mean <- apply(alpha.samples[, sub], 1, mean)
plot(alpha.true[, 1], alpha.hat.mean, pch = 19)
alpha.true <- dat$alpha
plot(alpha.true[, 1], alpha.hat.mean, pch = 19)
alpha.true
alpha.true <- dat$alpha
plot(alpha.true, alpha.hat.mean, pch = 19)
lines(alpha.true, alpha.true, col = 'red')
summary(mcmc(window(t(alpha.samples), start = burn.in)))
summary(mcmc(window(t(lambda.samples), start = burn.in)))
# Individual random effects
beta.hat.mean <- apply(beta.samples[, sub], 1, mean)
plot(beta.true[, 1], beta.hat.mean)
beta.true <- dat$beta
# Individual random effects
beta.hat.mean <- apply(beta.samples[, sub], 1, mean)
beta.true <- dat$beta
plot(beta.true, beta.hat.mean, pch = 19)
lines(beta.true, beta.true, col = 'red')
# Look at process varaince
plot(window(mcmc(sigma.sq.samples), start = burn.in), density = FALSE)
dat$sigma.sq
summary(window(mcmc(sigma.sq.samples), start = burn.in))
# Lambda covariance matrix
summary(window(mcmc(t(lambda.samples), start = burn.in))
# Lambda covariance matrix
summary(window(mcmc(t(lambda.samples), start = burn.in)))
# Lambda covariance matrix
summary(window(mcmc(t(lambda.samples)), start = burn.in)))
# Lambda covariance matrix
summary(window(mcmc(t(lambda.samples)), start = burn.in))
lambda.true <- dat$lambda
lambda.true
lambda.true <- c(dat$lambda)
lambda.true
rm(list = ls())
source("multivarSoundModel.R")
library(coda)
library(corrplot)
library(ggplot2)
library(dplyr)
# This is the main file for running the multivariate model described in
# Doser et al (2019) Assessing soundscape disturbance through hierarchical models
# and acoustic indices: a case study on a shelterwood logged northern Michigan forest.
# Also includes code for computation of figures for analysis of model.
# Note code for convergence assessment is not included in this file, but can be
# implemented in a similar manner as displayed in the univariateModel using
# the Gelman-Rubin diagnostic.
# Author: Jeffrey W. Doser
# Run model ---------------------------------------------------------------
n.iter <- 500
fileName <- "../../data/orderedMultivariateData.csv"
geoFileName <- "../../data/geophony.csv"
indexNames <- c('H', 'aci', 'ndsi', 'aei', paste('PSD', 1:10, sep = ''))
yearsPostTrt <- 2014:2018
alpha.start <- 1
beta.start <- 0
sigma.sq.start <- 1
lambda.start <- 1
out1 <- multivar.sound.model(n.iter = n.iter,
fileName,
geoFileName,
indexNames,
yearsPostTrt,
alpha.start,
beta.start,
sigma.sq.start,
lambda.start)
